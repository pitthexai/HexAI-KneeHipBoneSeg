{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e03e8c18",
   "metadata": {},
   "source": [
    "# U-Net on HexAI-HipKneeBonSeg dataset\n",
    "\n",
    "### U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5fc398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import ConvTranspose2d, Conv2d, MaxPool2d, ReLU\n",
    "from torchvision.transforms import CenterCrop\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_Channels, out_Channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(in_Channels, out_Channels, kernel_size=3, padding=1, padding_mode='replicate')\n",
    "        self.conv2 = Conv2d(out_Channels, out_Channels, kernel_size=3, padding=1, padding_mode='replicate')\n",
    "        self.ReLU = ReLU()\n",
    "        self.BatchNorm = torch.nn.BatchNorm2d(out_Channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_output = self.conv1(x)\n",
    "        conv1_output = self.BatchNorm(conv1_output)\n",
    "        conv2_input = self.ReLU(conv1_output)\n",
    "        conv2_output = self.conv2(conv2_input)\n",
    "        conv2_output = self.BatchNorm(conv2_output)\n",
    "        output = self.ReLU(conv2_output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, channels=[1, 64, 128, 256, 512, 1024]):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [Block(channels[i], channels[i + 1]) for i in range(0, len(channels) - 1)]\n",
    "        )\n",
    "        self.pooling_layer = MaxPool2d(kernel_size=2, stride=2)  # The kernel size for max pool in the U-net model is 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            outputs.append(x)\n",
    "            x = self.pooling_layer(x)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "\n",
    "class FinalBlock(nn.Module):\n",
    "    def __init__(self, in_Channels, hidden_Channels, out_Channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(in_Channels, hidden_Channels, kernel_size=3, padding=1, padding_mode='replicate')\n",
    "        self.conv2 = Conv2d(hidden_Channels, hidden_Channels, kernel_size=3, padding=1, padding_mode='replicate')\n",
    "        self.conv3 = Conv2d(hidden_Channels, out_Channels, kernel_size=1, padding=1, padding_mode='replicate')\n",
    "        self.batchnorm1 = nn.BatchNorm2d(hidden_Channels)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(out_Channels)\n",
    "        self.ReLU = ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_output = self.conv1(x)\n",
    "        conv1_output = self.batchnorm1(conv1_output)\n",
    "        conv2_input = self.ReLU(conv1_output)\n",
    "        conv2_output = self.conv2(conv2_input)\n",
    "        conv2_output = self.batchnorm1(conv2_output)\n",
    "        conv3_input = self.ReLU(conv2_output)\n",
    "        output = self.conv3(conv3_input)\n",
    "        output = self.batchnorm2(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.up_convs = nn.ModuleList(\n",
    "            [ConvTranspose2d(channels[i], channels[i + 1], kernel_size=2, stride=2)\n",
    "             for i in range(0, len(channels) - 2)]\n",
    "        )\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [Block(channels[i], channels[i + 1]) for i in range(0, len(channels) - 3)]\n",
    "        )\n",
    "        self.final_block = FinalBlock(channels[len(channels) - 3],  # in_channel\n",
    "                                      channels[len(channels) - 2],  # hidden_channel\n",
    "                                      channels[len(channels) - 1])  # out_channel\n",
    "\n",
    "\n",
    "    def forward(self, encoder_output):\n",
    "        x = encoder_output[len(encoder_output) - 1]  # get the output of the last layer of the encoder\n",
    "        x = self.up_convs[0](x)\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            enc_features = encoder_output[len(encoder_output) - i - 2]  # output of the same layer in encoder\n",
    "            enc_features = self.copy_and_crop(x, enc_features)\n",
    "            x = torch.cat([x, enc_features], dim=1)\n",
    "            x = block(x)\n",
    "            x = self.up_convs[i + 1](x)\n",
    "        enc_features = encoder_output[0]\n",
    "        enc_features = self.copy_and_crop(x, enc_features)\n",
    "        x = torch.cat([x, enc_features], dim=1)\n",
    "\n",
    "        return self.final_block(x)\n",
    "\n",
    "    def copy_and_crop(self, x, enc_features):\n",
    "        (_, _, H, W) = x.shape\n",
    "        enc_features = CenterCrop([H, W])(enc_features)\n",
    "        return enc_features\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, config, encoder_channels=[1, 64, 128, 256, 512, 1024],\n",
    "                 decoder_channels=[1024, 512, 256, 128, 64],\n",
    "                 retain_dim=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(encoder_channels)\n",
    "        decoder_channels.append(config.num_classes)\n",
    "        self.decoder = Decoder(decoder_channels)\n",
    "        self.output_size = config.image_shape\n",
    "        self.retain_dim = retain_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_outputs = self.encoder(x)\n",
    "        output = self.decoder(encoder_outputs)\n",
    "        if self.retain_dim:\n",
    "            output = F.interpolate(output, self.output_size)\n",
    "\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c8994c",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac28b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import SimpleITK as sitk\n",
    "import pydicom\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, paths, transforms_image, transforms_mask, transform_both=None):\n",
    "        self.path_to_images = paths['path_to_images']\n",
    "        self.path_to_masks = paths['path_to_masks']\n",
    "        self.transforms_image = transforms_image\n",
    "        self.transforms_mask = transforms_mask\n",
    "        self.transforms_both = transform_both\n",
    "        self.image_sizes = set()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path_to_images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.path_to_images[index]\n",
    "        image = pydicom.dcmread(image_path)\n",
    "        image = image.pixel_array\n",
    "        try:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        except:\n",
    "            pass\n",
    "        image = image.astype(np.uint8)\n",
    "        mask_path = self.path_to_masks[index]\n",
    "        mask = sitk.ReadImage(mask_path)\n",
    "        mask = sitk.GetArrayFromImage(mask)\n",
    "        if self.transforms_image is not None:\n",
    "            image = self.transforms_image(image)\n",
    "        if mask.ndim == 3 and mask.shape[2] == 3:  \n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "            mask = np.squeeze(mask)\n",
    "        if mask.ndim == 3 and mask.shape[2] != 3:\n",
    "            for i in range(mask.shape[0]):\n",
    "                if np.sum(mask[i, :, :]) > 0:\n",
    "                    mask = mask[i, :, :]\n",
    "                    mask = np.squeeze(mask)\n",
    "        mask = mask.astype(np.uint8)\n",
    "        if self.transforms_mask is not None:\n",
    "            if mask.ndim == 3:\n",
    "                mask = np.squeeze(mask)\n",
    "            if mask.ndim == 3:\n",
    "                mask = mask[0]\n",
    "                mask = np.squeeze(mask)\n",
    "            mask = self.transforms_mask(mask)\n",
    "        if self.transforms_both is not None:\n",
    "            stacked = torch.cat([image, mask], dim=0)  # shape=(2xHxW)\n",
    "            stacked = self.transforms_both(stacked)\n",
    "            image, mask = torch.chunk(stacked, chunks=2, dim=0)\n",
    "\n",
    "        mask = mask > 0\n",
    "        mask = mask.to(torch.float)\n",
    "        self.image_sizes.add(image.size())\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ad2f9",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a4e96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from imutils import paths\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from .dataset import Dataset, UnlabeledDataset, TestDataset\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_data(config):\n",
    "    \"\"\"\n",
    "    it loads train and test set given the path to all images.\n",
    "    :param config: initialized config class\n",
    "    :return: trainset and testset\n",
    "    \"\"\"\n",
    "    \n",
    "    image_paths = sorted(list(os.listdir(os.path.join(config.path_to_dataset, 'Images'))))\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        image_paths[i] = os.path.join(config.path_to_dataset, 'Images', image_path)\n",
    "    mask_paths = sorted(list(os.listdir(os.path.join(config.path_to_dataset, 'Annotations_NII'))))\n",
    "    for i, mask_path in enumerate(mask_paths):\n",
    "        mask_paths[i] = os.path.join(config.path_to_dataset, 'Annotations', mask_path)\n",
    "    \n",
    "    train_images, test_images, train_masks, test_masks = train_test_split(image_paths, mask_paths,\n",
    "                                                                          test_size=config.test_size, random_state=7)\n",
    "    with open(\"output.txt\", \"w\") as txt_file:\n",
    "        for line in test_images:\n",
    "            txt_file.write(line.split('/')[-1].split('.')[0] + \"\\n\") \n",
    "\n",
    "    transform_image = transforms.Compose([transforms.ToPILImage(),\n",
    "                                          transforms.Resize(config.input_size),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize(0.5, 0.1),\n",
    "                                          transforms.GaussianBlur(kernel_size=3)])\n",
    "    transform_mask = transforms.Compose([transforms.ToPILImage(),\n",
    "                                         transforms.Resize(config.input_size),\n",
    "                                         transforms.ToTensor()])\n",
    "    train_path = {'path_to_images': train_images, 'path_to_masks': train_masks}\n",
    "    test_path = {'path_to_images': test_images, 'path_to_masks': test_masks}\n",
    "    train_set = Dataset(paths=train_path, transforms_image=transform_image,\n",
    "                        transforms_mask=transform_mask)\n",
    "    transform_image = transforms.Compose([transforms.ToPILImage(),\n",
    "                                          transforms.Resize(config.input_size),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize(0.5, 0.1)])\n",
    "    transform_mask = transforms.Compose([transforms.ToPILImage(),\n",
    "                                         transforms.Resize(config.input_size),\n",
    "                                         transforms.ToTensor()])\n",
    "    test_set = Dataset(paths=test_path, transforms_image=transform_image, transforms_mask=transform_mask)\n",
    "    \n",
    "    print(f\"[INFO] found {len(train_set)} examples in the training set...\")\n",
    "    print(f\"[INFO] found {len(test_set)} examples in the test set...\")\n",
    "    train_loader = DataLoader(train_set, shuffle=True, batch_size=config.batch_size, num_workers=os.cpu_count())\n",
    "    test_loader = DataLoader(test_set, shuffle=False, batch_size=config.batch_size, num_workers=os.cpu_count())\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ab56cc",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f54dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "from torch.utils.data import DataLoader\n",
    "from .dataset import PseudoDataset\n",
    "from torch.nn.functional import sigmoid\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "\n",
    "class Train(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.results = {\"train_loss\": [], \"test_loss\": [], 'IoU': [], 'precision': [], 'recall': []}\n",
    "        self.epochs = self.config.num_epochs\n",
    "        self.pseudo_labels = []\n",
    "        self.pseudo_images = []\n",
    "        self.transform_image = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                   transforms.Resize(config.input_size),\n",
    "                                                   transforms.ToTensor(),\n",
    "                                                   transforms.Normalize(0.5, 0.1),\n",
    "                                                   transforms.GaussianBlur(kernel_size=3)])\n",
    "        self.transform_mask = transforms.Compose([transforms.ToPILImage(),\n",
    "                                                  transforms.Resize(config.input_size),\n",
    "                                                  transforms.ToTensor()])\n",
    "        \n",
    "\n",
    "    def train(self, model, train_steps, train_loader, test_steps, test_loader, unlabeled_loader):\n",
    "\n",
    "        loss_function_CE = CrossEntropyLoss()\n",
    "        optimizer = SGD(model.parameters(), lr=self.config.lr, momentum=self.config.momentum)\n",
    "        scheduler = ExponentialLR(optimizer, gamma=0.8)\n",
    "        start_time = time.time()\n",
    "\n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            for (i, (image, mask)) in enumerate(train_loader):\n",
    "                (image, mask) = (image.to(device=self.config.device), mask.to(device=self.config.device))\n",
    "                prediction = model(image)\n",
    "                loss = loss_function_CE(prediction, mask)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss\n",
    "                if i % 10 == 0:\n",
    "                    print(f'Train loss in epoch {epoch} and on batch {i} is: {loss}')\n",
    "                    p = sigmoid(prediction)[0].cpu().detach().numpy()\n",
    "                    p = p[0]\n",
    "                    plt.imshow((p > 0.5) * 255)\n",
    "                    plt.show()\n",
    "                    plt.imshow(mask.cpu()[0][0])\n",
    "                    plt.show()\n",
    "            torch.save(model, os.path.join(self.config.path_to_models,\n",
    "                                           ''.join(['epoch', str(epoch %5 + 1), '.pth'])))\n",
    "            \n",
    "            scheduler.step()\n",
    "        end_time = time.time()\n",
    "        print(\"[INFO] total time taken to train the model: {:.2f}s\".format(end_time - start_time))\n",
    "        return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fdca7e",
   "metadata": {},
   "source": [
    "### Config\n",
    "\n",
    "create a config similar to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38288ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "import wandb\n",
    "from ast import literal_eval\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "DATASET = 'JHIR_Knee'\n",
    "MODEL = 'U-Net'\n",
    "PRETRAINED = 'True'\n",
    "PATH_TO_DATA = './data'\n",
    "DATASET_FOLDER = 'JHIR_Hip_Knee_Datasets/Knee'\n",
    "PATH_TO_MODELS = './models'\n",
    "PATH_TO_REPORTS = './reports'\n",
    "PATH_TO_RESULTS = './results'\n",
    "TEST_SIZE = '0.2'\n",
    "LEARNING_RATE = '2e-2'\n",
    "MOMENTUM = '9e-1'\n",
    "OPTIMIZER = 'sgd'\n",
    "LOSS = 'BCE'\n",
    "NUM_CLASSES = '9'\n",
    "BATCH_SIZE = '16'\n",
    "NUM_EPOCHS = '10000'\n",
    "SCHEDULER_GAMMA = '0.98'\n",
    "INPUT_SIZE = '(224,224)'\n",
    "DATA_READ = 'hard'\n",
    "AUGMENTATION = 'False'\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "\n",
    "def parse_args(arguments=None):\n",
    "    parser = argparse.ArgumentParser(description=\"Total Knee Replacement Prediction Task\")\n",
    "    parser.add_argument(\n",
    "        \"-m\", \"--model\",\n",
    "        default=MODEL,\n",
    "        help=\"model\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-pt\", \"--pretrained\",\n",
    "        default=PRETRAINED,\n",
    "        help=\"pretrained\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-ds\", \"--dataset_name\",\n",
    "        default=DATASET,\n",
    "        help=\"dataset name\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-ptd\", \"--path_to_data\",\n",
    "        default=PATH_TO_DATA,\n",
    "        help=\"path to the data folder\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-dsf\", \"--dataset_folder\",\n",
    "        default=DATASET_FOLDER,\n",
    "        help=\"dataset folder\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-ptds\", \"--path_to_dataset\",\n",
    "        default=os.path.join(PATH_TO_DATA, DATASET_FOLDER),\n",
    "        help=\"path to the dataset folder\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-ptm\", \"--path_to_models\",\n",
    "        default=PATH_TO_MODELS,\n",
    "        help=\"path to models\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-ptrp\", \"--path_to_reports\",\n",
    "        default=PATH_TO_REPORTS,\n",
    "        help=\"path to reports to be saved\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-ptrs\", \"--path_to_results\",\n",
    "        default=PATH_TO_RESULTS,\n",
    "        help=\"path to outputs of the generation model to be saved\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-ts\", \"--test_size\",\n",
    "        default=TEST_SIZE,\n",
    "        help=\"test size for train test split\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-lr\", \"--learning_rate\",\n",
    "        default=LEARNING_RATE,\n",
    "        help=\"enter the learning rate\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-mo\", \"--momentum\",\n",
    "        default=MOMENTUM,\n",
    "        help=\"Enter momentum value\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-o\", \"--optimizer\",\n",
    "        default=OPTIMIZER,\n",
    "        help=\"optimizer\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-l\", \"--loss\",\n",
    "        default=LOSS,\n",
    "        help=\"loss type\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-nc\", \"--num_classes\",\n",
    "        default=NUM_CLASSES,\n",
    "        help=\"number of classes for classification\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-bc\", \"--batch_size\",\n",
    "        default=BATCH_SIZE,\n",
    "        help=\"batch size in the training phase\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-ne\", \"--num_epochs\",\n",
    "        default=NUM_EPOCHS,\n",
    "        help=\"number of epochs in training phase\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-sg\", \"--scheduler_gamma\",\n",
    "        default=SCHEDULER_GAMMA,\n",
    "        help=\"value of gamma for exponential lr scheduler\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-is\", \"--input_size\",\n",
    "        default=INPUT_SIZE,\n",
    "        help=\"the size of the input to the model\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-dr\", \"--data_read\",\n",
    "        default=DATA_READ,\n",
    "        help=\"choose if you want to keep data in hard or memory\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-ag\", \"--augmentation\",\n",
    "        default=AUGMENTATION,\n",
    "        help=\"Does training include augmentation\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-th\", \"--threshold\",\n",
    "        default=THRESHOLD,\n",
    "        help=\"threshold for classifier of the segmentation model\"\n",
    "    )\n",
    "    args = parser.parse_args(arguments)\n",
    "    return args\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        args = parse_args()\n",
    "        self.device = DEVICE\n",
    "        self.model = args.model\n",
    "        self.pretrained = (args.pretrained == 'True')\n",
    "        self.augmentation = (args.augmentation == 'True')\n",
    "        self.dataset = args.dataset_name\n",
    "        self.path_to_data = args.path_to_data\n",
    "        self.dataset_folder = args.dataset_folder\n",
    "        self.path_to_dataset = args.path_to_dataset\n",
    "        self.path_to_models = args.path_to_models\n",
    "        os.makedirs(self.path_to_models, exist_ok=True)\n",
    "        os.makedirs(os.path.join(self.path_to_models, self.model), exist_ok=True)\n",
    "        self.reports_path = args.path_to_reports\n",
    "        os.makedirs(self.reports_path, exist_ok=True)\n",
    "        self.results_path = args.path_to_results\n",
    "        os.makedirs(self.results_path, exist_ok=True)\n",
    "        self.test_size = float(args.test_size)\n",
    "        self.lr = float(args.learning_rate)\n",
    "        self.momentum = float(args.momentum)\n",
    "        self.optimizer = args.optimizer\n",
    "        self.loss = args.loss\n",
    "        self.num_classes = int(args.num_classes)\n",
    "        self.num_epochs = int(args.num_epochs)\n",
    "        self.batch_size = int(args.batch_size)\n",
    "        self.scheduler_gamma = float(args.scheduler_gamma)\n",
    "        self.image_shape = literal_eval(args.input_size)\n",
    "        self.input_size = literal_eval(args.input_size)\n",
    "        self.data_read = args.data_read\n",
    "        self.threshold = args.threshold\n",
    "        self.evaluation = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7c2b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Config\n",
    "from model import UNet, UNetPretrained\n",
    "import utils as utils\n",
    "from train import Train\n",
    "import torch\n",
    "import os\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    config = Config()\n",
    "   \n",
    "    train = Train(config)\n",
    "    model = UNet(config).to(device=config.device)\n",
    "    model = model.to(device=config.device)\n",
    "    train_loader, test_loader, unlabeled_loader = utils.load_data(config)\n",
    "    train_steps = len(train_loader)\n",
    "    test_steps = len(test_loader)\n",
    "    model = train.train(model=model, train_steps=train_steps, train_loader=train_loader,\n",
    "                            test_steps=test_steps, test_loader=test_loader, unlabeled_loader=unlabeled_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
